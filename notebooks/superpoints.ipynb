{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "1e7ee052a0259041"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/552 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     EPE      AS     AR  Angle    Out  Eval_Time\n",
      "0  0.178  63.614  74.46  0.313  0.024       1.97\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import time\n",
    "\n",
    "# Adjacent NN for motion segmentation\n",
    "from data.dataloader import SFDataset4D, compensate_ego_motion, construct_global_poses_from_relative\n",
    "from pytorch3d.ops.knn import knn_points\n",
    "from vis.deprecated_vis import *\n",
    "from loss.flow import DT\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import DBSCAN\n",
    "from torch_scatter import scatter\n",
    "from ops.metric import SceneFlowMetric\n",
    "from models.RSNF import RigidNeuralPriorV2, NeuralPrior\n",
    "from models.jointST import STNeuralPrior, MultiRigidNeuralPrior\n",
    "from benchmark.evaluation import get_datetime\n",
    "\n",
    "plt.close()\n",
    "\n",
    "# Data\n",
    "device = torch.device('cuda:0')\n",
    "motion_metric = 0.05\n",
    "eps = 0.15\n",
    "\n",
    "max_flow_epoch = 200\n",
    "loss_diff_stop = 0.001\n",
    "early_patience = 100\n",
    "verbose = True\n",
    "COMPENSATE_EGO = False\n",
    "\n",
    "dataset = SFDataset4D(dataset_type='waymo', n_frames=1, only_first=True)\n",
    "\n",
    "\n",
    "exp_folder = f'/mnt/personal/vacekpa2/experiments/' + 'development_metric'\n",
    "os.makedirs(f'{exp_folder}', exist_ok=True)\n",
    "runs = 1\n",
    "\n",
    "for run in range(runs):\n",
    "    cfg = {'param' : 1, 'eps' : 0.15, 'run' : run}\n",
    "    My_metric = SceneFlowMetric()\n",
    "        \n",
    "    for i, data in enumerate(tqdm(dataset)):\n",
    "        data = dataset[4]\n",
    "        \n",
    "        if COMPENSATE_EGO: # with options\n",
    "            data = compensate_ego_motion(data)\n",
    "            # missing compensation to pc2\n",
    "            data['pc1'] = data['global_pc1']\n",
    "            data['pc2'] = data['global_pc2']\n",
    "             \n",
    "        # Unpack Data\n",
    "        data['pc1'] = data['pc1'].to(device)\n",
    "        data['pc2'] = data['pc2'].to(device)\n",
    "        data['gt_flow'] = data['gt_flow'].to(device)\n",
    "        data['id_mask1'] = data['id_mask1'].to(device)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # model = RigidNeuralPriorV2(lr=0.008, early_stop=100, verbose=True).to(device) # better!\n",
    "        # model = NeuralPrior(lr=0.008, early_stop=500, verbose=False).to(device)\n",
    "        # model = STNeuralPrior(eps=eps, lr=0.003, cluster_every_iter=1000, refine=False, early_stop=500, verbose=False).to(device)\n",
    "        model = MultiRigidNeuralPrior(eps=eps, lr=0.008, cluster_every_iter=10000, refine=False, early_stop=10, verbose=False).to(device)\n",
    "        \n",
    "    \n",
    "        # visualize_multiple_pcls(*[a.detach().cpu().numpy(), pc2[0].detach().cpu().numpy()])\n",
    "        \n",
    "        output_data = model(data)\n",
    "        My_metric.update(output_data)\n",
    "        # print('\\r\\033[2K\\033[1G', end='', flush=True)   # this shift to one line up\n",
    "    \n",
    "        if i == 0: break\n",
    "        \n",
    "    # store metrics as file and plot?\n",
    "    # visualize_flow3d(data['pc1'][0], data['pc2'][0], data['pred_flow'][0])\n",
    "    # visualize_points3D(data['pc1'][0], data['id_mask1'][0])\n",
    "    epe = (data['pred_flow'][0] - data['gt_flow'][0,:,:3]).norm(dim=-1) # masking\n",
    "    # visualize_points3D(data['pc1'][0], epe)\n",
    "    print(My_metric.get_metric())\n",
    "    \n",
    "    path = exp_folder + '/' + get_datetime()\n",
    "    df = My_metric.get_metric()\n",
    "    \n",
    "    os.makedirs(f'{path}', exist_ok=True)\n",
    "    df.to_csv(path + '/metric.csv')\n",
    "    \n",
    "    import pandas as pd\n",
    "    cfg_df = pd.DataFrame(cfg, index=[0])\n",
    "    cfg_df.to_csv(path + '/config.csv')\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T12:54:01.289630893Z",
     "start_time": "2023-11-06T12:53:50.495665203Z"
    }
   },
   "id": "bf387af5c0fb6971"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# metric DO NOT delete\n",
    "# import glob\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# exp_folder = f'/mnt/personal/vacekpa2/experiments/' + 'development_metric'\n",
    "# all_paths = sorted(glob.glob(exp_folder + '/*'))\n",
    "# \n",
    "# for path in all_paths:\n",
    "#     \n",
    "#     metric_df = pd.read_csv(path + '/metric.csv', index_col=0)\n",
    "#     cfg_df = pd.read_csv('tse.csv', index_col=0).iloc[0]    \n",
    "    \n",
    "import torch \n",
    "\n",
    "from models.RSNF import NeuralPriorNetwork\n",
    "from loss.flow import GeneralLoss, chamfer_distance_loss\n",
    "from models.scoopy.get_model import PretrainedSCOOP\n",
    "from ops.metric import SceneFlowMetric\n",
    "from data.dataloader import SFDataset4D\n",
    "from vis.deprecated_vis import imshow, plt\n",
    "# cfg\n",
    "plt.close()\n",
    "device = torch.device('cuda:0')\n",
    "net = PretrainedSCOOP().to(device)\n",
    "\n",
    "\n",
    "dataset = SFDataset4D(dataset_type='kitti_t', n_frames=1, only_first=True)\n",
    "data = dataset[0]\n",
    "pc1 = data['pc1'][:1].to(device)\n",
    "pc2 = data['pc2'][:1].to(device)\n",
    "# net = NeuralPriorNetwork().to(device)\n",
    "\n",
    "LossModule = GeneralLoss(pc1,pc2,K=32,sm_normals_K=5, smooth_weight=10., forward_weight=1, pc2_smooth=True)\n",
    "metric = SceneFlowMetric()\n",
    "# todo cfgs, ablation \n",
    "# kitti cfg, ablaiton on weights\n",
    "net.update(pc1, pc2)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.008)\n",
    "\n",
    "for i in tqdm(range(10)):\n",
    "    \n",
    "    pred_flow = net(pc1)\n",
    "    data['pred_flow'] = pred_flow\n",
    "    # dist_loss, _, _ = chamfer_distance_loss(pc1 + pred_flow, pc2, both_ways=True)\n",
    "    loss = LossModule(pc1, pred_flow, pc2)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    # print(i, loss)\n",
    "    # criterion of convergence\n",
    "metric.update(data) # per one iteration\n",
    "    \n",
    "metric.get_metric()\n",
    "plt.plot(metric.get_metric()['EPE'])\n",
    "imshow(plt)\n",
    "# visualize_flow3d(pc1[0], pc2[0], pred_flow[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-05T08:40:24.579566344Z"
    }
   },
   "id": "9046ad398dd3d010"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Instance segmentace\n",
    "# Rigid instance v case\n",
    "# 1) ST clustering, smoothnes, dbscan, ID indicator is enough\n",
    "# 2) Rigid centroids as in rigid loss\n",
    "# 3) Regularize flow over centroids which should backpropagate directly to flow\n",
    "# 4) Trajectory consistency keep objects with missing next measurement headed in the same direction\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d19653134c8f95e5"
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.84 ms ± 414 ns per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    },
    {
     "data": {
      "text/plain": "torch.Size([100000, 800])"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "pred_mask = torch.rand((100000, 3), device=device)\n",
    "centroids = torch.rand((800, 3), device=device)\n",
    "\n",
    "\n",
    "# find closest centroids to pred_mask\n",
    "centroids = centroids.unsqueeze(0).repeat(pred_mask.shape[0], 1, 1)\n",
    "pred_mask = pred_mask.unsqueeze(1).repeat(1, centroids.shape[1], 1)\n",
    "%timeit dist = (centroids - pred_mask).norm(dim=-1, p=1).argmin(dim=-1)\n",
    "dist.shape\n",
    "\n",
    "# db_mask = DBSCAN(eps=0.8, min_samples=30).fit_predict(data['pc1'][0].detach().cpu().numpy())\n",
    "# visualize_points3D(data['pc1'][0], db_mask)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T15:51:13.556189296Z",
     "start_time": "2023-11-01T15:50:43.111231075Z"
    }
   },
   "id": "8a68075f81fa5adc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Freespace"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "554c1d440429b76a"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# dataset = SFDataset4D(dataset_type='waymo', n_frames=1, only_first=True)\n",
    "# data = dataset[4]\n",
    "pc1 = data['pc1']\n",
    "pc2 = data['pc2']\n",
    "flow = data['pred_flow']\n",
    "nbr_pts = 100\n",
    "meters = 3\n",
    "ray_flow = pc2.repeat(nbr_pts, 1, 1)\n",
    "indices = torch.arange(0, end=nbr_pts, step=1, device=pc2.device).unsqueeze(-1).unsqueeze(-1) / nbr_pts\n",
    "ray_flow_points = ray_flow * indices \n",
    "\n",
    "# inside?\n",
    "from loss.flow import DT\n",
    "\n",
    "pc = pc2\n",
    "\n",
    "# calc_depth = pc[:,:3].norm(dim=1)\n",
    "# yaw = - torch.arctan2(pc[:, 1], pc[:, 0])\n",
    "# pitch = torch.arcsin(pc[:, 2] / (calc_depth + 1e-8))\n",
    "# \n",
    "# px = (yaw - yaw.min()) / self.vert_fov * (self.W - 1)\n",
    "# py = (pitch - pitch.min()) / self.hor_fov * (self.H - 1)        \n",
    "\n",
    "# DT_layer = DT(pc1 + flow, ray_flow_points.view(1,-1,3))\n",
    "# dt_loss, dist = DT_layer.torch_bilinear_distance(pc1 + flow)\n",
    "\n",
    "# visualize_points3D(pc1[0]+flow[0], dist)\n",
    "# visualize_flow3d(data['pc1'][0], data['pc2'][0], data['pred_flow'][0])\n",
    "# visualize_multiple_pcls(*[(pc1+flow)[0].detach().cpu().numpy(), pc1[0,:1].detach().cpu().numpy(), ray_flow_points.view(-1,3).detach().cpu().numpy(), pc2[0].detach().cpu().numpy()])\n",
    "visualize_multiple_pcls(*[(pc1+flow)[0].detach().cpu().numpy(), pc2[0].detach().cpu().numpy()])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-02T08:19:42.169136461Z",
     "start_time": "2023-11-02T08:19:41.329539568Z"
    }
   },
   "id": "877f3dbba33baa9f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Notes\n",
    "- rigidity works even for one points\n",
    "- maybe weight unmatched clusters?\n",
    "- Waymo 4 sequence case for freespace\n",
    "    - Only unique first encountered points, measurements are noisy in distances  "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a47d531b2697bc20"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# All cluster rigidity loss"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "94faf951ced3117c"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "# from vis.deprecated_vis import *\n",
    "# %matplotlib notebook\n",
    "from IPython.display import HTML\n",
    "import matplotlib.animation\n",
    "from tqdm import tqdm\n",
    "from models.MBNSF.utils import sc_utils\n",
    "from sklearn.cluster import DBSCAN\n",
    "from torch_scatter import scatter\n",
    "pc1 = data['pc1']\n",
    "pc2 = data['pc2']\n",
    "cluster_ids = DBSCAN(0.8, min_samples=30).fit_predict(pc1[0].detach().cpu().numpy())\n",
    "cluster_ids = torch.from_numpy(cluster_ids).float().clone().to(pc1.device)\n",
    "data['pred_inst'] = cluster_ids.unsqueeze(0).clone()\n",
    "cluster_ids = data['pred_inst'] + 1 # 0 is noise points, maybe drop all together. In Instance seg, its a background usually\n",
    "cluster_ids = cluster_ids.long()\n",
    "# cluster_ids = data['pred_inst']\n",
    "flow = data['pred_flow'].clone().detach().requires_grad_(True)\n",
    "optimizer = torch.optim.Adam([flow], lr=0.003)\n",
    "\n",
    "# visualize_points3D(pc1[0], cluster_ids[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-03T09:12:08.991773461Z",
     "start_time": "2023-11-03T09:12:06.907106968Z"
    }
   },
   "id": "f9831694632cfe19"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "def center_rigidity_loss(pc1, flow, cluster_ids):\n",
    "    '''\n",
    "    For batch size of 1\n",
    "    :param pc1: \n",
    "    :param flow: \n",
    "    :param cluster_ids: \n",
    "    :return: \n",
    "    '''\n",
    "    pts_centers = scatter(pc1, cluster_ids, dim=1, reduce='mean')\n",
    "    flow_centers = scatter(pc1 + flow, cluster_ids, dim=1, reduce='mean')\n",
    "    \n",
    "    pt_dist_to_center = (pc1 - pts_centers[0, cluster_ids[0]].unsqueeze(0))#.norm(dim=-1, p=1)\n",
    "    flow_dist_to_center = ((pc1 + flow) - flow_centers[0, cluster_ids[0]].unsqueeze(0))#.norm(dim=-1, p=1)\n",
    "    \n",
    "    center_displacement = pt_dist_to_center - flow_dist_to_center\n",
    "    \n",
    "    rigidity_loss = center_displacement.norm(dim=-1).mean()\n",
    "\n",
    "    return rigidity_loss"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T12:57:59.098263288Z",
     "start_time": "2023-11-01T12:57:59.006695205Z"
    }
   },
   "id": "f9859da6829bf9d5"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 102.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# opt_flow = flow.clone().detach().requires_grad_(True)\n",
    "init_flow = torch.rand(flow.shape, device=pc1.device) + 2\n",
    "opt_flow = init_flow.clone().requires_grad_(True)\n",
    "optimizer = torch.optim.Adam([opt_flow], lr=0.01)\n",
    "\n",
    "# nice!!!\n",
    "for i in tqdm(range(100)):\n",
    "    rigid_loss = center_rigidity_loss(pc1, opt_flow, cluster_ids)\n",
    "    rigid_loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "visualize_multiple_pcls(*[pc1[0].detach().cpu().numpy(), (pc1[0] + opt_flow[0]).detach().cpu().numpy(), (pc1[0] + init_flow[0]).detach().cpu().numpy()])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T13:42:53.823890547Z",
     "start_time": "2023-11-01T13:42:52.821323095Z"
    }
   },
   "id": "d22979f43fec4dcc"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "visualize_points3D(pc1[0], cluster_ids[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-01T13:09:28.481480056Z",
     "start_time": "2023-11-01T13:09:28.448964343Z"
    }
   },
   "id": "27f0976df7ff0d03"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:07<00:00,  5.99it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# from vis.deprecated_vis import *\n",
    "# %matplotlib notebook\n",
    "from IPython.display import HTML\n",
    "import matplotlib.animation\n",
    "from tqdm import tqdm\n",
    "from models.MBNSF.utils import sc_utils\n",
    "from sklearn.cluster import DBSCAN\n",
    "pc1 = data['pc1']\n",
    "pc2 = data['pc2']\n",
    "cluster_ids = DBSCAN(0.8, min_samples=30).fit_predict(pc1[0].detach().cpu().numpy())\n",
    "cluster_ids = torch.from_numpy(cluster_ids).float().clone().to(pc1.device)\n",
    "data['pred_inst'] = cluster_ids.unsqueeze(0).clone()\n",
    "cluster_ids = data['pred_inst']\n",
    "# cluster_ids = data['pred_inst']\n",
    "flow = data['pred_flow']\n",
    "\n",
    "# visualize_points3D(pc1[0], cluster_ids)\n",
    "object_id = 128\n",
    "c_pc = pc1[0, cluster_ids[0] == object_id]\n",
    "c_flow = flow[0, cluster_ids[0] == object_id].clone().detach().requires_grad_(True)\n",
    "\n",
    "optimizer = torch.optim.Adam([c_flow], lr=0.003)\n",
    "\n",
    "d_thre = 0.03\n",
    "src_keypts = c_pc.unsqueeze(0)\n",
    "tgt_keypts = (c_pc + c_flow).unsqueeze(0)\n",
    "fig, ax = plt.subplots(1,2)\n",
    "\n",
    "for i in tqdm(range(45)):\n",
    "    # iso_loss = sc_utils.spatial_consistency_loss(c_pc.unsqueeze(0), (c_pc + c_flow).unsqueeze(0), d_thre=d_thre)\n",
    "\n",
    "    # # Spatial Consistency Adjacency Matrix\n",
    "    src_dist = torch.norm((src_keypts[:, :, None, :] - src_keypts[:, None, :, :]), dim=-1)\n",
    "    target_dist = torch.norm((tgt_keypts[:, :, None, :] - tgt_keypts[:, None, :, :]), dim=-1)\n",
    "    cross_dist = torch.abs(src_dist - target_dist)\n",
    "    adj_mat = torch.clamp(1.0 - cross_dist ** 2 / d_thre ** 2, min=0)\n",
    "    # divergence is because of lack of |p| = 1?\n",
    "    # n = adj_mat.shape[1]\n",
    "    iso_loss = ((adj_mat - 1) ** 2).mean()\n",
    "    # print(adj_mat.mean())\n",
    "    loss = - torch.log( iso_loss.mean())\n",
    "    loss = iso_loss.mean()\n",
    "    loss.backward()\n",
    "    \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    # print(i, loss)\n",
    "    plt.close()\n",
    "    plt.axis('equal')\n",
    "    ax[0].imshow(adj_mat[0][:512,:512].detach().cpu().numpy())\n",
    "    ax[0].set_title(loss.item())\n",
    "    ax[1].scatter(c_pc[:,0].detach().cpu().numpy(), c_pc[:,1].detach().cpu().numpy(), c=c_pc[:,2].detach().cpu().numpy(), s=1)\n",
    "    ax[1].quiver(c_pc[:,0].detach().cpu().numpy(), c_pc[:,1].detach().cpu().numpy(), c_flow[:,0].detach().cpu().numpy(), c_flow[:,1].detach().cpu().numpy(), color='r',\n",
    "                 scale=1, scale_units='xy')\n",
    "    path = '/mnt/personal/vacekpa2/vis/current/'\n",
    "    fig.savefig(f'{path}/{i}.png', dpi=100)\n",
    "    ax[0].cla()\n",
    "    ax[1].cla()\n",
    "    \n",
    "\n",
    "\n",
    "path = '/mnt/personal/vacekpa2/vis/current/'\n",
    "# plt.savefig(f'{path}/{i}.png', dpi=200)\n",
    "# imshow(fig=plt)\n",
    "# plt.close()\n",
    "# plt.imshow(adj_mat[0].detach().cpu().numpy())\n",
    "# imshow(fig=plt)\n",
    "\n",
    "# if os.path.exists(f'{path}/out.mp4'):\n",
    "#     os.remove(f'{path}/out.mp4')\n",
    "\n",
    "# os.system(f\"ffmpeg -framerate 15 -pattern_type glob -i '{path}/*.png' -c:v libx264 -pix_fmt yuv420p {path}/out.mp4 > /dev/null\")\n",
    "# HTML(ani.to_jshtml())\n",
    "\n",
    "# plt.savefig('test.png')\n",
    "\n",
    "# visualize_flow3d(c_pc, c_pc + c_flow, c_flow)\n",
    "# visualize_points3D(c_pc, c_pc[:, 2])\n",
    "# visualize_flow3d(pc1[0], pc2[0], flow[0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T08:16:37.353502348Z",
     "start_time": "2023-11-06T08:16:27.837167624Z"
    }
   },
   "id": "53a3541c325aeafe"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Per cluster rigidity loss"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77cded5e0b77624"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:00<00:13,  7.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.]], device='cuda:0', requires_grad=True)\n",
      "tensor([[ 0.1000, -0.1000,  0.1000]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:00<00:12,  7.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0256, -0.0256,  0.1841]], device='cuda:0', requires_grad=True)\n",
      "tensor([[-0.0602,  0.0602,  0.2061]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:00<00:12,  7.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0822,  0.0824,  0.2062]], device='cuda:0', requires_grad=True)\n",
      "tensor([[-0.0702,  0.0708,  0.1548]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [00:00<00:12,  7.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0371,  0.0385,  0.1625]], device='cuda:0', requires_grad=True)\n",
      "tensor([[ 0.0100, -0.0077,  0.2103]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [00:01<00:11,  7.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0304, -0.0266,  0.2675]], device='cuda:0', requires_grad=True)\n",
      "tensor([[ 0.0303, -0.0251,  0.3160]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [00:01<00:11,  7.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0141, -0.0080,  0.3568]], device='cuda:0', requires_grad=True)\n",
      "tensor([[-0.0150,  0.0217,  0.3883]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [00:01<00:11,  7.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0259,  0.0324,  0.4186]], device='cuda:0', requires_grad=True)\n",
      "tensor([[-0.0217,  0.0278,  0.4484]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [00:01<00:10,  7.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0049,  0.0103,  0.4774]], device='cuda:0', requires_grad=True)\n",
      "tensor([[ 0.0224, -0.0179,  0.5045]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [00:02<00:10,  7.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0333, -0.0296,  0.5552]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [00:02<00:13,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0303, -0.0270,  0.6190]], device='cuda:0', requires_grad=True)\n",
      "tensor([[ 0.0153, -0.0124,  0.6823]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [00:02<00:11,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0101,  0.0108,  0.7537]], device='cuda:0', requires_grad=True)\n",
      "tensor([[-0.0213,  0.0179,  0.8294]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [00:02<00:10,  7.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0198,  0.0125,  0.9087]], device='cuda:0', requires_grad=True)\n",
      "tensor([[-0.0072, -0.0032,  0.9838]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [00:03<00:10,  7.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0151, -0.0057,  1.0525]], device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0239, 0.0036, 1.1161]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [00:03<00:09,  7.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0207, 0.0014, 1.1751]], device='cuda:0', requires_grad=True)\n",
      "tensor([[ 0.0071, -0.0110,  1.2298]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [00:03<00:09,  7.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0158, -0.0109,  1.2802]], device='cuda:0', requires_grad=True)\n",
      "tensor([[-2.5439e-02,  1.4230e-04,  1.3258e+00]], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [00:04<00:09,  7.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.3283e-02, -2.6207e-04,  1.3665e+00]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([[-0.0106,  0.0101,  1.4031]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [00:04<00:08,  7.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0113, 0.0091, 1.4361]], device='cuda:0', requires_grad=True)\n",
      "tensor([[ 0.0205, -0.0022,  1.4663]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [00:04<00:08,  7.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0183, -0.0017,  1.4941]], device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0060, 0.0091, 1.5197]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [00:04<00:10,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0154,  0.0085,  1.5430]], device='cuda:0', requires_grad=True)\n",
      "tensor([[-0.0241, -0.0023,  1.5641]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [00:05<00:08,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0216, -0.0017,  1.5834]], device='cuda:0', requires_grad=True)\n",
      "tensor([[-0.0089,  0.0091,  1.6009]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [00:05<00:07,  7.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0127, 0.0086, 1.6169]], device='cuda:0', requires_grad=True)\n",
      "tensor([[ 0.0220, -0.0020,  1.6314]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42/100 [00:05<00:07,  7.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.9960e-02, -1.3926e-03,  1.6449e+00]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([[0.0079, 0.0094, 1.6573]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 44/100 [00:05<00:07,  7.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0131,  0.0089,  1.6686]], device='cuda:0', requires_grad=True)\n",
      "tensor([[-0.0218, -0.0017,  1.6789]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 46/100 [00:06<00:06,  7.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.9382e-02, -1.1049e-03,  1.6883e+00]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([[-0.0070,  0.0096,  1.6969]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 48/100 [00:06<00:06,  7.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0142, 0.0091, 1.7048]], device='cuda:0', requires_grad=True)\n",
      "tensor([[ 2.3099e-02, -1.5513e-03,  1.7120e+00]], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [00:06<00:06,  7.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.0885e-02, -9.9004e-04,  1.7188e+00]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([[0.0087, 0.0096, 1.7251]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 52/100 [00:06<00:06,  7.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0124,  0.0090,  1.7309]], device='cuda:0', requires_grad=True)\n",
      "tensor([[-2.1284e-02, -1.6173e-03,  1.7362e+00]], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 54/100 [00:07<00:07,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.9153e-02, -1.1039e-03,  1.7411e+00]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([[-0.0071,  0.0094,  1.7456]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 56/100 [00:07<00:06,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0137, 0.0088, 1.7497]], device='cuda:0', requires_grad=True)\n",
      "tensor([[ 0.0224, -0.0018,  1.7536]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 58/100 [00:07<00:05,  7.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.0008e-02, -1.3002e-03,  1.7573e+00]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([[0.0077, 0.0092, 1.7608]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60/100 [00:08<00:05,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0134,  0.0086,  1.7641]], device='cuda:0', requires_grad=True)\n",
      "tensor([[-0.0223, -0.0020,  1.7671]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 62/100 [00:08<00:04,  7.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.0294e-02, -1.4409e-03,  1.7699e+00]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([[-0.0084,  0.0091,  1.7723]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 64/100 [00:08<00:04,  7.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0124, 0.0085, 1.7746]], device='cuda:0', requires_grad=True)\n",
      "tensor([[ 0.0209, -0.0020,  1.7767]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 66/100 [00:08<00:04,  7.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.8523e-02, -1.4308e-03,  1.7789e+00]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([[0.0063, 0.0091, 1.7811]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 68/100 [00:09<00:04,  7.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0148,  0.0086,  1.7832]], device='cuda:0', requires_grad=True)\n",
      "tensor([[-0.0238, -0.0019,  1.7850]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70/100 [00:09<00:03,  7.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.1742e-02, -1.2395e-03,  1.7866e+00]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([[-0.0099,  0.0094,  1.7880]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 72/100 [00:09<00:04,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0108, 0.0089, 1.7892]], device='cuda:0', requires_grad=True)\n",
      "tensor([[ 1.9395e-02, -1.5016e-03,  1.7905e+00]], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 74/100 [00:10<00:03,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.7023e-02, -8.1438e-04,  1.7919e+00]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([[0.0048, 0.0099, 1.7934]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 76/100 [00:10<00:03,  7.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0162,  0.0095,  1.7949]], device='cuda:0', requires_grad=True)\n",
      "tensor([[-2.5071e-02, -8.4151e-04,  1.7960e+00]], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 78/100 [00:10<00:02,  7.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.3010e-02, -6.7395e-05,  1.7969e+00]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "tensor([[-0.0111,  0.0107,  1.7975]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80/100 [00:10<00:02,  7.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0096, 0.0104, 1.7980]], device='cuda:0', requires_grad=True)\n",
      "tensor([[1.8180e-02, 1.2747e-04, 1.7986e+00]], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 82/100 [00:11<00:02,  7.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0158, -0.0191,  1.7994]], device='cuda:0', requires_grad=True)\n",
      "tensor([[ 0.0037, -0.0262,  1.8005]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 84/100 [00:11<00:02,  7.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0173, -0.0226,  1.8016]], device='cuda:0', requires_grad=True)\n",
      "tensor([[-0.0261, -0.0091,  1.8025]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 86/100 [00:11<00:01,  7.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0241,  0.0131,  1.8030]], device='cuda:0', requires_grad=True)\n",
      "tensor([[-0.0122,  0.0230,  1.8034]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 88/100 [00:11<00:01,  7.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0085, 0.0220, 1.8037]], device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0171, 0.0111, 1.8042]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90/100 [00:12<00:01,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0147, -0.0088,  1.8050]], device='cuda:0', requires_grad=True)\n",
      "tensor([[ 0.0026, -0.0165,  1.8060]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 92/100 [00:12<00:01,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0184, -0.0134,  1.8069]], device='cuda:0', requires_grad=True)\n",
      "tensor([[-2.7201e-02, -5.6381e-04,  1.8075e+00]], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 94/100 [00:12<00:00,  7.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0252,  0.0211,  1.8078]], device='cuda:0', requires_grad=True)\n",
      "tensor([[-0.0133,  0.0306,  1.8080]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 96/100 [00:13<00:00,  7.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0073, 0.0291, 1.8083]], device='cuda:0', requires_grad=True)\n",
      "tensor([[0.0159, 0.0177, 1.8089]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 98/100 [00:13<00:00,  7.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0135, -0.0025,  1.8098]], device='cuda:0', requires_grad=True)\n",
      "tensor([[ 1.3336e-03, -1.0605e-02,  1.8108e+00]], device='cuda:0',\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:13<00:00,  7.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0196, -0.0078,  1.8118]], device='cuda:0', requires_grad=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from ops.transform import xyz_axis_angle_to_matrix, matrix_to_xyz_axis_angle\n",
    "\n",
    "object_id = 128\n",
    "c_pc = pc1[0, cluster_ids[0] == object_id]\n",
    "c_flow = flow[0, cluster_ids[0] == object_id].clone().detach().requires_grad_(True)\n",
    "\n",
    "c_flow = torch.rand(c_pc.shape, device=c_flow.device) * 0.3\n",
    "c_flow = c_flow.float().unsqueeze(0).requires_grad_(True)\n",
    "yaw_rotation = torch.zeros(1, 3, device=c_flow.device, requires_grad=True)\n",
    "optimizer = torch.optim.Adam([c_flow, yaw_rotation], lr=0.1)\n",
    "\n",
    "src_keypts = c_pc.unsqueeze(0)\n",
    "tgt_keypts = (c_pc + c_flow).unsqueeze(0)\n",
    "# how to deal with Noisy points?\n",
    "\n",
    "\n",
    "# todo instance probs, allowed rotation of displacement\n",
    "random_yaw = torch.zeros(1, 3, device=c_flow.device)\n",
    "random_yaw[0, 2] = 0.4\n",
    "random_translation = torch.rand(1, 3, device=c_flow.device)\n",
    "\n",
    "transform = xyz_axis_angle_to_matrix(torch.cat((random_translation, random_yaw), dim=1)).to(device)\n",
    "\n",
    "target_pc = (c_pc[:,:3] @ transform[0, :3,:3] + transform[0,:3,3]).unsqueeze(0) # transform okay I guess\n",
    "\n",
    "# todo continue here\n",
    "yaw = yaw_rotation[0, 2]\n",
    "inst_probs = torch.ones(1, c_pc.shape[0], dtype=torch.float, device=c_flow.device)\n",
    "\n",
    "# print(target_pc.shape)\n",
    "# visualize_multiple_pcls(*[c_pc.detach().cpu().numpy(), target_pc[0].detach().cpu().numpy()])\n",
    "\n",
    "plt.close()\n",
    "fig, ax = plt.subplots(1,2) \n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    \n",
    "    center = (src_keypts.mean(dim=1)).unsqueeze(1)\n",
    "    # target_pt = (src_keypts.mean(dim=1) + 1).unsqueeze(1)\n",
    "    flow_center = ((src_keypts + c_flow).mean(dim=1)).unsqueeze(1)\n",
    "    \n",
    "    rot_mat = (xyz_axis_angle_to_matrix(torch.cat((torch.zeros(1, 3, device=c_flow.device), yaw_rotation), dim=1)).to(device))\n",
    "    \n",
    "     \n",
    "    \n",
    "    rotated_flows = ((c_flow - c_flow.mean(dim=1)) @ rot_mat[:,:3,:3]) + c_flow.mean(dim=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # dist_to_center = (center[..., :2] - src_keypts[..., :2]).norm(dim=-1, p=1)\n",
    "    # flow_dist_to_center = (flow_center[..., :2] - (src_keypts[..., :2] + c_flow[..., :2])).norm(dim=-1, p=1)\n",
    "    # exact dimension from center\n",
    "    residual_from_center = (center[..., :2] - src_keypts[..., :2]) - (flow_center[..., :2] - (src_keypts[..., :2] + c_flow[..., :2]))\n",
    "    # rigidity_loss = (dist_to_center - flow_dist_to_center).abs()\n",
    "    rigidity_loss = residual_from_center.abs().mean(dim=-1)\n",
    "    \n",
    "    # version with ||d||\n",
    "    # rigidity_loss = ((center[..., :2] - src_keypts[..., :2]).norm(dim=-1) - (flow_center[..., :2] - (src_keypts[..., :2] + c_flow[..., :2])).norm(dim=-1)).abs()\n",
    "    # maybe enought with NN\n",
    "    \n",
    "    # flow_dist_to_target = (target_pc[..., :2] - (src_keypts[..., :2] + c_flow[..., :2])).norm(dim=-1, p=1)\n",
    "    flow_dist_to_target, nn_ind, _ = knn_points((src_keypts[..., :2] + c_flow[..., :2]), target_pc[..., :2])\n",
    "    \n",
    "\n",
    "    rot_dist, _, _ = knn_points(rotated_flows[..., :2], target_pc[..., :2])\n",
    "    # push all residual to the mean (points should move isometrically and no point should diverge from the mean)\n",
    "    # loss = (residual_dist - mean_residual).mean() #+ flow_dist_to_center.mean()\n",
    "    # loss = rigidity_loss.mean()\n",
    "    loss = flow_dist_to_target.mean() + 3 * rigidity_loss.mean() + rot_dist.mean() + yaw_rotation[:,:2].abs().mean()\n",
    "    # residual_dist.shape, flow_dist_to_center.shape, dist_to_center.shape, mean_residual\n",
    "    loss.backward()\n",
    "    \n",
    "    print(yaw_rotation)\n",
    "    \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    # # print(i, loss)\n",
    "    plt.close()\n",
    "    plt.axis('equal')\n",
    "    \n",
    "    ax[0].plot(rigidity_loss[0].detach().cpu().numpy(), '.')\n",
    "    ax[0].set_ylim(0, 0.4)\n",
    "    ax[1].axis('equal')\n",
    "    # ax[0].imshow(adj_mat[0][:512,:512].detach().cpu().numpy())\n",
    "    \n",
    "    ax[1].set_title(f\"Iter: {i:03d} Loss: {loss.item():.4f}\")\n",
    "    # ax[1].set_xlim(21, 24)\n",
    "    # ax[1].set_ylim(8, 10)\n",
    "    ax[1].scatter(c_pc[:,0].detach().cpu().numpy(), c_pc[:,1].detach().cpu().numpy(), c=rigidity_loss[0].detach().cpu().numpy(), s=5)\n",
    "    ax[1].scatter(center.view(-1,3)[:,0].detach().cpu().numpy(), center.view(-1,3)[:,1].detach().cpu().numpy(), c='k', marker='*', s=30)\n",
    "    ax[1].scatter(flow_center.view(-1,3)[:,0].detach().cpu().numpy(), flow_center.view(-1,3)[:,1].detach().cpu().numpy(), c='g', marker='*', s=30)\n",
    "    ax[1].scatter(target_pc.view(-1,3)[:,0].detach().cpu().numpy(), target_pc.view(-1,3)[:,1].detach().cpu().numpy(), c='r', marker='.', s=5)\n",
    "    ax[1].scatter((c_pc + rotated_flows.view(-1,3))[:,0].detach().cpu().numpy(), (c_pc + rotated_flows.view(-1,3))[:,1].detach().cpu().numpy(), c='k', marker='.', s=5, alpha=0.2)\n",
    "    ax[1].scatter((c_pc[:, 0] +  c_flow[0,:,0]).detach().cpu().numpy(), (c_pc[:, 1] +  c_flow[0,:,1]).detach().cpu().numpy(), c='g', marker='.', s=5)\n",
    "    \n",
    "    # faking quiver is wrong animation\n",
    "    # ax[1].quiver(c_pc[:,0].detach().cpu().numpy(), c_pc[:,1].detach().cpu().numpy(), c_flow[0,:,0].detach().cpu().numpy(), c_flow[0,:,1].detach().cpu().numpy(), color='g',\n",
    "    #              scale=1, scale_units='xy')\n",
    "    path = '/mnt/personal/vacekpa2/vis/current/'\n",
    "    fig.savefig(f'{path}/{i}.png', dpi=100)\n",
    "    ax[0].cla()\n",
    "    ax[1].cla()\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T08:16:51.700084414Z",
     "start_time": "2023-11-06T08:16:37.361338013Z"
    }
   },
   "id": "12d58138855749b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Case study"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1dd5690d281836b3"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2007 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'flow'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [2], line 96\u001B[0m\n\u001B[1;32m     93\u001B[0m grid_factor \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m10\u001B[39m\n\u001B[1;32m     95\u001B[0m \u001B[38;5;66;03m# just quick iteration over dataset\u001B[39;00m\n\u001B[0;32m---> 96\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m f, data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(tqdm(dataset)):\n\u001B[1;32m     97\u001B[0m     \u001B[38;5;66;03m# *_, data = dataset\u001B[39;00m\n\u001B[1;32m     98\u001B[0m     \u001B[38;5;66;03m# if f != 26:\u001B[39;00m\n\u001B[1;32m     99\u001B[0m     \u001B[38;5;66;03m#     continue\u001B[39;00m\n\u001B[1;32m    101\u001B[0m     pc1 \u001B[38;5;241m=\u001B[39m data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpc1\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m    102\u001B[0m     pc2 \u001B[38;5;241m=\u001B[39m data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpc2\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[0;32m/mnt/appl/software/tqdm/4.64.0-GCCcore-11.3.0/lib/python3.10/site-packages/tqdm/std.py:1195\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1192\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[1;32m   1194\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1195\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[1;32m   1196\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[1;32m   1197\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[1;32m   1198\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[0;32m~/4D-RNSFP/data/dataloader.py:76\u001B[0m, in \u001B[0;36mNSF_dataset.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     73\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n\u001B[1;32m     74\u001B[0m \u001B[38;5;66;03m# print(self.idx)\u001B[39;00m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;66;03m# self.idx += 1\u001B[39;00m\n\u001B[0;32m---> 76\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__getitem__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43midx\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/4D-RNSFP/data/dataloader.py:87\u001B[0m, in \u001B[0;36mNSF_dataset.__getitem__\u001B[0;34m(self, idx)\u001B[0m\n\u001B[1;32m     85\u001B[0m pc1 \u001B[38;5;241m=\u001B[39m data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpc1\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     86\u001B[0m pc2 \u001B[38;5;241m=\u001B[39m data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpc2\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m---> 87\u001B[0m gt_flow \u001B[38;5;241m=\u001B[39m \u001B[43mdata\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mflow\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m     91\u001B[0m pc1, pc2, gt_flow \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpreprocess_func(pc1, pc2, gt_flow)\n\u001B[1;32m     93\u001B[0m pc1 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mfrom_numpy(pc1)\u001B[38;5;241m.\u001B[39munsqueeze(\u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mto(torch\u001B[38;5;241m.\u001B[39mfloat32)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'flow'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pytorch3d.transforms import axis_angle_to_matrix\n",
    "from sklearn.cluster import DBSCAN\n",
    "from data.PATHS import DATA_PATH\n",
    "from loss.flow import *\n",
    "\n",
    "from vis.deprecated_vis import *\n",
    "from models.simple_models import InstanceSegModule, FlowSegPrior, Weights_model, JointFlowInst\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from loss.flow import chamfer_distance_loss, GeneralLoss, FastNN\n",
    "from loss.instance import DynamicLoss, InstanceSmoothnessLoss\n",
    "from loss.utils import find_robust_weighted_rigid_alignment\n",
    "from models.RSNF import NeuralPriorNetwork,RigidMovementPriorNetwork\n",
    "from loss.flow import DT\n",
    "\n",
    "from torch_scatter import scatter\n",
    "from ops.metric import SceneFlowMetric\n",
    "from data.dataloader import NSF_dataset\n",
    "\n",
    "class JointModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, pc1, instances=10, init_cluster=None):\n",
    "        super().__init__()\n",
    "        self.instances = instances\n",
    "        \n",
    "        if init_cluster:\n",
    "            # print('clustering')\n",
    "            # oversegmentation\n",
    "            clusters = DBSCAN(0.3, min_samples=5).fit_predict(pc1[0].detach().cpu().numpy()) + 1\n",
    "            \n",
    "            instances = clusters.max()\n",
    "            # split to mask\n",
    "            mask = torch.zeros((1, pc1.shape[1], instances), device=device)\n",
    "            for i in range(instances):  # can be speed up\n",
    "                mask[0, clusters == i, i] = 1\n",
    "            self.mask = torch.nn.Parameter(mask, requires_grad=True)\n",
    "            # visualize_points3D(pc1[0], mask.argmax(dim=2)[0])\n",
    "        else:\n",
    "            self.mask = torch.nn.Parameter(torch.randn(1, pc1.shape[1], instances, requires_grad=True))\n",
    "            \n",
    "        self.flow_net = RigidMovementPriorNetwork()\n",
    "\n",
    "        # todo add boxes here?\n",
    "    def forward(self, pc1, pc2=None):\n",
    "\n",
    "        output = self.flow_net(pc1)\n",
    "        mask = self.mask.softmax(dim=2)\n",
    "        \n",
    "        # Assign rigid parameters\n",
    "        t = output[:,:, :3]\n",
    "        yaw = output[:,:, 3:4]\n",
    "        \n",
    "        # construct rotation\n",
    "        full_rotvec = torch.cat((torch.zeros((1, yaw.shape[1], 2), device=device), yaw), dim=-1)\n",
    "        rot_mat = axis_angle_to_matrix(full_rotvec.squeeze(0)) # this is lot, but still okay\n",
    "        \n",
    "        # construct centroids\n",
    "        ind = torch.argmax(mask, dim=2).squeeze(0)\n",
    "        v_max = scatter(pc1[0], ind, dim=0, reduce='max')  \n",
    "        v_min = scatter(pc1[0], ind, dim=0, reduce='min') \n",
    "        x_c = (v_max + v_min) / 2\n",
    "        \n",
    "        # shift points\n",
    "        point_x_c = x_c[ind]\n",
    "        \n",
    "        \n",
    "        deformed_pc = (rot_mat @ (pc1 - point_x_c).permute(1, 2, 0)).permute(2, 0, 1) + point_x_c + t\n",
    "        \n",
    "        pred_flow = deformed_pc - pc1\n",
    "        \n",
    "        return pred_flow, mask, t, yaw\n",
    "        # return pred_flow, mask\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(0)\n",
    "    else:\n",
    "        device = torch.device('cpu')\n",
    "    \n",
    "    metric = SceneFlowMetric()\n",
    "    dataset_type = 'ft3d'\n",
    "    # dataset = NSF_dataset(dataset_type=dataset_type)\n",
    "    dataset = NSF_dataset(dataset_type=dataset_type)\n",
    "    \n",
    "    K = 32\n",
    "    max_radius = 1\n",
    "    grid_factor = 10\n",
    "    \n",
    "    # just quick iteration over dataset\n",
    "    for f, data in enumerate(tqdm(dataset)):\n",
    "        # *_, data = dataset\n",
    "        # if f != 26:\n",
    "        #     continue\n",
    "        \n",
    "        pc1 = data['pc1'].to(device)\n",
    "        pc2 = data['pc2'].to(device)\n",
    "        gt_flow = data['gt_flow'].to(device)\n",
    "    \n",
    "        \n",
    "        st = time.time()\n",
    "        model = JointModel(pc1, instances=30, init_cluster=True).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        # losses\n",
    "        # sm_normals_K = 4 for sota\n",
    "        LossModule = GeneralLoss(pc1=pc1, pc2=pc2, dist_mode='DT', K=K, max_radius=max_radius, smooth_weight=1, forward_weight=0, sm_normals_K=0, pc2_smooth=True)\n",
    "        \n",
    "        \n",
    "        for flow_e in range(150):\n",
    "    \n",
    "            pc1 = pc1.contiguous()\n",
    "            pred_flow, mask, t, yaw = model(pc1)    # Model outputs directly mask and predicted flow\n",
    "            \n",
    "            # for mask prob\n",
    "            # mask_probs = mask.max(dim=2)[0]\n",
    "            # forw_dist, forward_nn, _ = knn_points(pc1 + pred_flow, pc2, lengths1=None, lengths2=None, K=1, norm=1)\n",
    "            # back_dist, backward_nn, _ = knn_points(pc2, pc1 + pred_flow, lengths1=None, lengths2=None, K=1, norm=1)\n",
    "            # dist_loss = ((forw_dist).mean() + (back_dist).mean()) / 2\n",
    "            \n",
    "            # dist_loss = ((forw_dist * mask_probs).mean() + (back_dist).mean()) / 2\n",
    "            \n",
    "            data['pred_flow'] = pred_flow\n",
    "            \n",
    "            loss = LossModule(pc1, pred_flow, pc2)\n",
    "            inst_smooth, _ = LossModule.smoothness_loss(mask, LossModule.NN_pc1)    # added instances\n",
    "            trans_smooth, _ = LossModule.smoothness_loss(t, LossModule.NN_pc1)    # added instances\n",
    "            yaw_smooth, _ = LossModule.smoothness_loss(yaw, LossModule.NN_pc1)    # added instances\n",
    "            \n",
    "            # regularizations\n",
    "            # loss += inst_smooth.mean() + trans_smooth.mean() + yaw_smooth.mean() + (yaw ** 2).mean() #+ (pred_flow.norm(dim=-1)).mean() * 10\n",
    "            \n",
    "            \n",
    "            loss.mean().backward()\n",
    "    \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "    \n",
    "            # print(f\"Iter: {flow_e:03d} \\t Loss: {loss.mean().item():.4f} \\t Flow: {loss.mean().item():.4f} \"\n",
    "            #       f\"\\t Smoothness: {inst_smooth.mean().item():.4f} \"\n",
    "                  # f\"Cycle: {cycle_smooth_flow.mean().item():.4f} \\t Dynamic: {dynamic_loss.mean().item():.4f} \\t\"\n",
    "                  # f\"RMSD: {rmsd.mean().item():.4f} \\t Kabsch_w: {kabsch_w.mean().item():.4f}\"\n",
    "                  # )\n",
    "            \n",
    "        data['eval_time'] = time.time() - st\n",
    "        data['pc1'] = pc1\n",
    "        data['pc2'] = pc2\n",
    "        data['gt_flow'] = gt_flow\n",
    "        metric.update(data)\n",
    "        \n",
    "        break\n",
    "        \n",
    "    print(metric.get_metric())\n",
    "    print(metric.get_metric().mean())\n",
    "    instance_classes = torch.argmax(mask, dim=2)[0].squeeze(0).detach().cpu().numpy()\n",
    "    # visualize_points3D(pc1[0].detach().cpu().numpy(), instance_classes)\n",
    "    # visualize_flow3d(pc1[0].detach().cpu().numpy(), pc2[0].detach().cpu().numpy(), pred_flow[0].detach().cpu().numpy())\n",
    "    # visualize_points3D(pc1[0].detach().cpu().numpy(), instance_classes == 0)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-07T07:58:03.400384548Z",
     "start_time": "2023-11-07T07:58:02.602803079Z"
    }
   },
   "id": "fe8c20fad7208690"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "EPE           0.026\nAS           97.608\nAR           98.571\nAngle         0.109\nOut           0.104\nEval_Time     4.801\ndtype: float64"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance_classes = torch.argmax(mask, dim=2)[0].squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "# visualize_points3D(pc1[0].detach().cpu().numpy(), instance_classes)\n",
    "# visualize_flow3d(pc1[0].detach().cpu().numpy(), pc2[0].detach().cpu().numpy(), pred_flow[0].detach().cpu().numpy())\n",
    "# visualize_flow3d(pc1[0].detach().cpu().numpy(), pc2[0].detach().cpu().numpy(), gt_flow[0].detach().cpu().numpy())\n",
    "# df_mask = (metric.get_metric()['EPE'] < 0.2)\n",
    "# metric.get_metric()[df_mask].mean()\n",
    "metric.get_metric().mean()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-06T16:45:48.141245782Z",
     "start_time": "2023-11-06T16:45:48.129974421Z"
    }
   },
   "id": "cc448f81f9b7cb55"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# centroids\n",
    "from torch_scatter import scatter\n",
    "\n",
    "a = c_pc[0, mos]\n",
    "# ids from dbscan\n",
    "ind = torch.tensor(ids, device=device) + 1  # what about -1?\n",
    "\n",
    "# print(a.shape, ind.shape)\n",
    "# print(ind.max())\n",
    "# centroid = scatter(a, ind, dim=0, reduce='mean')\n",
    "v_max = scatter(a, ind, dim=0, reduce='max')  \n",
    "v_min = scatter(a, ind, dim=0, reduce='min') \n",
    "\n",
    "flow_vectors = scatter(forth_flow[0, mos], ind, dim=0, reduce='mean')\n",
    "\n",
    "flow_magnitudes = flow_vectors.norm(dim=1, p=1)\n",
    "yaw_from_flow = torch.arctan2(flow_vectors[:,1], flow_vectors[:,0]) # in radians\n",
    "\n",
    "yaw_from_flow[ind]\n",
    "box_corners = torch.stack([v_max, v_min], dim=1)    # for vis?\n",
    "centroids = (v_max + v_min) / 2\n",
    "\n",
    "# lwh - rotate points around centroids with flow(~yaw) angle and find max and min in dimensions\n",
    "# can be extended to 3D,for simplicity only 2D now\n",
    "rot_mat = torch.stack([torch.cos(yaw_from_flow), -torch.sin(yaw_from_flow), torch.sin(yaw_from_flow), torch.cos(yaw_from_flow)], dim=1).view(-1, 2, 2)\n",
    "\n",
    "# rotate points\n",
    "broadcasted_rot_mat = rot_mat[ind]\n",
    "shifted_points = a - centroids[ind]\n",
    "\n",
    "res = broadcasted_rot_mat @ shifted_points[:,:2].unsqueeze(-1)\n",
    "\n",
    "res = torch.cat((res, a[:, 2:3].unsqueeze(-1) - centroids[ind, 2:3].unsqueeze(-1)), dim=1).squeeze(-1) + centroids[ind]\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# do not forget about noise points, that are now ind 0!!!\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# print(broadcasted_rot_mat.shape, shifted_points.shape, res.shape)\n",
    "visualize_multiple_pcls(*[c_pc[0, mos].detach().cpu().numpy(), centroids.detach().cpu().numpy(), res.detach().cpu().numpy()])\n",
    "\n",
    "# rotated points\n",
    "shifted_limits_max = scatter(res, ind, dim=0, reduce='max')\n",
    "shifted_limits_min = scatter(res, ind, dim=0, reduce='min')\n",
    "\n",
    "lwh = shifted_limits_max - shifted_limits_min\n",
    "\n",
    "boxes = torch.cat((centroids, lwh, yaw_from_flow.unsqueeze(-1)), dim=1)\n",
    "\n",
    "from data.box_utils import get_bbox_points\n",
    "box_points = get_bbox_points(boxes[1:].detach().cpu())  # drop noise points\n",
    "visualize_multiple_pcls(*[c_pc[0, mos].detach().cpu().numpy(), centroids.detach().cpu().numpy(), box_points])\n",
    "# visualize_points3D(box_points, box_points[:,3])\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d9320797096f7f9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Next steps\n",
    "- Iterative spatio-temporal clustering with warped flow\n",
    "\n",
    "- box after rotation (x=16.25, y=-8.8, z=0.3)\n",
    "- gradiently enlarge boxes \n",
    "- Freespace to divide boxes or make them smaller\n",
    "- Linear motion\n",
    "- NP experiments\n",
    "- How to merge, how to coverage?\n",
    "- Coverage, calculate DT/NN between boxes and points, increase coverage to nearby points"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "17cfeaf0636de049"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "506d5df3d092c628"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
