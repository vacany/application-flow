{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T11:46:00.083564311Z",
     "start_time": "2023-10-02T11:46:00.068504168Z"
    }
   },
   "outputs": [],
   "source": [
    "# All in Torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# We will need pytorch3d\n",
    "from pytorch3d.transforms import  euler_angles_to_matrix\n",
    "\n",
    "\n",
    "def construct_transform(rotation_vector : torch.Tensor, translation : torch.Tensor):\n",
    "    '''\n",
    "    Construct 4x4 transformation matrix from rotation vector and translation vector while perserving differentiation\n",
    "    :param rotation_vector: \n",
    "    :param translation: \n",
    "    :return: Pose matrix\n",
    "    '''    \n",
    "    assert rotation_vector.shape == (3,)\n",
    "    assert translation.shape == (1,3)\n",
    "    \n",
    "    rotation = euler_angles_to_matrix(rotation_vector, convention='XYZ')\n",
    "    \n",
    "    r_t_matrix = torch.hstack([rotation, translation.T])\n",
    "    \n",
    "    pose = torch.vstack([r_t_matrix, torch.tensor([[0,0,0,1]], device=rotation.device)])\n",
    "    \n",
    "    return pose\n",
    "\n",
    "class PoseTransform(torch.nn.Module):\n",
    "    '''\n",
    "    Pose transform layer\n",
    "    Works as a differentiable transformation layer to fit rigid ego-motion\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, device='cpu'):\n",
    "        super().__init__()\n",
    "        # If not working in sequences, use LieTorch\n",
    "        self.translation = torch.nn.Parameter(torch.zeros((1,3), requires_grad=True, device=device))\n",
    "        self.rotation_angles = torch.nn.Parameter(torch.tensor([0., 0., 0.], requires_grad=True, device=device))\n",
    "        # self.pose = construct_transform(self.rotation_angles, self.translation).T.unsqueeze(0)\n",
    "    \n",
    "    def construct_pose(self):\n",
    "        self.pose = construct_transform(self.rotation_angles, self.translation).T.unsqueeze(0)\n",
    "        \n",
    "        return self.pose    \n",
    "        \n",
    "    def forward(self, pc):\n",
    "        \n",
    "        pc_to_transform = torch.cat([pc, torch.ones((1, pc.shape[1], 1), device=pc.device)], dim=2)\n",
    "        \n",
    "        pose = construct_transform(self.rotation_angles, self.translation).T.unsqueeze(0)\n",
    "        \n",
    "        deformed_pc = torch.bmm(pc_to_transform, pose)[:,:,:3]\n",
    "        \n",
    "        return deformed_pc\n",
    "\n",
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        m.bias.data.fill_(0.0)\n",
    "\n",
    "class RigidNeuralPrior(torch.nn.Module):\n",
    "    '''\n",
    "    Neural Prior with Rigid Transformation, takes only point cloud t=1 on input and returns flow and rigid flow (ego-motion flow)\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, pc1, dim_x=3, filter_size=128, act_fn='relu', layer_size=8):\n",
    "        super().__init__()\n",
    "        self.layer_size = layer_size\n",
    "        self.RigidTransform = PoseTransform(device=pc1.device)\n",
    "        # testing refinement\n",
    "        self.Refinement = torch.nn.Parameter(torch.randn(pc1.shape, requires_grad=True))\n",
    "        bias = True\n",
    "        self.nn_layers = torch.nn.ModuleList([])\n",
    "        \n",
    "        # input layer (default: xyz -> 128)\n",
    "        if layer_size >= 1:\n",
    "            self.nn_layers.append(torch.nn.Sequential(torch.nn.Linear(dim_x, filter_size, bias=bias)))\n",
    "            if act_fn == 'relu':\n",
    "                self.nn_layers.append(torch.nn.ReLU())\n",
    "            elif act_fn == 'sigmoid':\n",
    "                self.nn_layers.append(torch.nn.Sigmoid())\n",
    "            for _ in range(layer_size-1):\n",
    "                self.nn_layers.append(torch.nn.Sequential(torch.nn.Linear(filter_size, filter_size, bias=bias)))\n",
    "                if act_fn == 'relu':\n",
    "                    self.nn_layers.append(torch.nn.ReLU())\n",
    "                elif act_fn == 'sigmoid':\n",
    "                    self.nn_layers.append(torch.nn.Sigmoid())\n",
    "            self.nn_layers.append(torch.nn.Linear(filter_size, dim_x, bias=bias))\n",
    "        else:\n",
    "            self.nn_layers.append(torch.nn.Sequential(torch.nn.Linear(dim_x, dim_x, bias=bias)))\n",
    "        \n",
    "        self.initialize()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\" Points -> Flow\n",
    "            [B, N, 3] -> [B, N, 3]\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        deformed_pc = self.RigidTransform(x)\n",
    "        rigid_flow = deformed_pc - x\n",
    "        \n",
    "        # x = self.Refinement / 10 + rigid_flow\n",
    "        for layer in self.nn_layers:\n",
    "            # deformed_pc = layer(deformed_pc)\n",
    "            x = layer(x)\n",
    "        \n",
    "        final_flow = x + rigid_flow\n",
    "        \n",
    "        return final_flow, rigid_flow\n",
    "    \n",
    "    def initialize(self):\n",
    "        self.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a46311e9ae67cb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T11:46:00.457819952Z",
     "start_time": "2023-10-02T11:46:00.447763586Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports once\n",
    "# import sys\n",
    "# sys.path.append('../')\n",
    "from data.dataloader import NSF_dataset, SFDataset4D\n",
    "from loss.flow import DT, SmoothnessLoss\n",
    "from ops.metric import scene_flow_metrics\n",
    "from vis.deprecated_vis import visualize_points3D, visualize_multiple_pcls, visualize_flow3d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91250173123f7f1a",
   "metadata": {},
   "source": [
    "# Notes\n",
    "### todo add refinement layer to dynamic?\n",
    "### todo freespace flow refinement\n",
    "### todo NN index \"distance\" transform\n",
    "    - construct points around the original point cloud in another dimension (each point has its surroundings a row means index) [x]\n",
    "    - distance is coded as a order in which points goes (for example, you add points in one \"cell\" and those are first, adjacent two cells are seconds) [x]\n",
    "    - overlapping points that are \"more distant\" comes later along the axis, so if you order the final value backwards, the closest should be in the voxel\n",
    "    - this can maybe be generalizable into K-NN? Such as using K voxel grids and unique indices?\n",
    "    - task for Ruslan? [x]\n",
    "    - precision is cell size, because we do not know which one is closer in that cell. Well we know because of values and they can be subtracted, but that might be to much of a hassle. And cell can encode only one value, so we are bounded by this one\n",
    "    - max_radius parameter defines the amount of constructed points\n",
    "    - you can construct all points and then sort it based on distance to the central points\n",
    "    \n",
    "### todo one batch is one sequence processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15723ca6ba119f5c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-10-02T11:50:54.850102149Z"
    }
   },
   "outputs": [],
   "source": [
    "### Main training loop\n",
    "\n",
    "dataset = NSF_dataset()\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "for frame_id, data in enumerate(dataset):\n",
    "    if frame_id != 3:\n",
    "        continue\n",
    "    pc1, pc2, gt_flow = data['pc1'], data['pc2'], data['gt_flow']\n",
    "    \n",
    "    pc1 = pc1.to(device)\n",
    "    pc2 = pc2.to(device)\n",
    "    \n",
    "    # One model per both frames\n",
    "    model = RigidNeuralPrior(pc1, 3, 128, 'relu', 8).to(device)\n",
    "    # model = Neural_Prior(3, 128, 'relu', 8).to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.008)\n",
    "            \n",
    "    # Smooth_layer = SmoothnessLoss(pc1, pc2, K=8, sm_normals_K=0, smooth_weight=1, VA=False, max_radius=2, forward_weight=0, pc2_smooth=False, dataset='argoverse')\n",
    "    DT_layer = DT(pc1, pc2)\n",
    "    \n",
    "    # Iteration of losses\n",
    "    for e in range(300):\n",
    "        # deformed_pc = Transform_layer(pc1)\n",
    "        # pred_flow = model(pc1)\n",
    "        pred_flow, rigid_flow = model(pc1)\n",
    "        \n",
    "        dt_loss, per_point_dt_loss = DT_layer.torch_bilinear_distance(pc1 + pred_flow)\n",
    "        # velocity_loss = \n",
    "        rigid_dt_loss, _ = DT_layer.torch_bilinear_distance(pc1 + rigid_flow)\n",
    "        # smooth_loss, per_point_smooth_loss = Smooth_layer.smoothness_loss(pred_flow, Smooth_layer.NN_pc1, Smooth_layer.loss_norm)\n",
    "        \n",
    "        # truncated at two meters\n",
    "        # dt_loss = per_point_dt_loss[per_point_dt_loss < 2].mean()\n",
    "        \n",
    "        deformed_pc = pc1 + pred_flow\n",
    "    \n",
    "        # (dt_loss).backward()\n",
    "        # Loss\n",
    "        (dt_loss + rigid_dt_loss).backward()\n",
    "        # (dt_loss + smooth_loss + rigid_dt_loss).backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        print(f\"Epoch: {e:03d}, NN Loss: {dt_loss.item():.3f} \\t Rigid Loss: {rigid_dt_loss.item():.3f}\")\n",
    "        \n",
    "        \n",
    "    break    \n",
    "    \n",
    "\n",
    "# Way how to extract rigid transformation pose\n",
    "computed_pose = model.RigidTransform.construct_pose()\n",
    "\n",
    "# Computation of sceneflow metrics\n",
    "epe, accs, accr, angle, outlier = scene_flow_metrics(pred_flow, gt_flow.to(device))\n",
    "\n",
    "# Display metrics\n",
    "import pandas as pd\n",
    "# set pandas display options for float precision\n",
    "pd.set_option(\"display.precision\", 3)\n",
    "metric_df = pd.DataFrame([epe, accs, accr, angle, outlier], index=['epe', 'accs', 'accr', 'angle', 'outlier']).T\n",
    "\n",
    "metric_df.describe()\n",
    "\n",
    " \n",
    "# Visualization\n",
    "# visualize_points3D(pc1[0, :, :3].detach(), epe.detach()[0])\n",
    "# visualize_flow3d(pc1[0, :, :3].detach().cpu(), pc2[0, :, :3].detach().cpu(), pred_flow.detach()[0].cpu())\n",
    "# visualize_flow3d(pc1[0, :, :3].detach().cpu(), pc2[0, :, :3].detach().cpu(), gt_flow.detach()[0].cpu())\n",
    "# visualize_multiple_pcls(*[pc1[0, :, :3].detach().cpu(), deformed_pc[0, :, :3].detach().cpu(), pc2[0,:,:3].detach().cpu()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b158b8d4fcc287",
   "metadata": {},
   "source": [
    "# Notes\n",
    "- Prio: Fast testing of models in dev mode\n",
    "  - [x] connect Jupyter \n",
    "    - [ ] Framework \n",
    "    \n",
    "- RigidNeuralPrior can fit as a regular neural prior after some (tested in 500 epochs) iterations\n",
    "- Transform and refinement layer works, but lacks regularization, that maybe cyclic smoothness provides (todo experiment)\n",
    "- If NN in refinement has big weight, it deforms quickly\n",
    "- Add same flow along z-axis as it is in gravity when we know the transformation (todo experiment)\n",
    "- In this sample, the transformation is fitted correctly\n",
    "- With Neural Prior, it will never be correct transformation, since Neural Prior can compensate translation with bias? But bias is only 1 number\n",
    "- Paralel computation of Prior and Transformation? (todo experiment)\n",
    "- Fit transformation first, then fit (Sequentialy/jointly) neural prior? (todo experiment)\n",
    "- How to trust rigid transform more? (todo experiment)\n",
    "- How to find robust transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732e992da0e0c9b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T11:46:34.010096334Z",
     "start_time": "2023-10-02T11:46:33.978077712Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
